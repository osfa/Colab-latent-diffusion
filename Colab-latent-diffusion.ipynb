{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-latent-diffusion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Colab-latent-diffusion\n",
        "\n",
        "Original repo: [CompVis/latent-diffusion](https://github.com/CompVis/latent-diffusion)\n",
        "\n",
        "My fork: [styler00dollar/Colab-latent-diffusion](https://github.com/styler00dollar/Colab-latent-diffusion)"
      ],
      "metadata": {
        "id": "z5TrMDlHA2Ru"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tfvH5bAgFUt"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install (~30min)\n",
        "%cd /content/\n",
        "!git clone https://github.com/CompVis/latent-diffusion\n",
        "!mkdir /content/input\n",
        "!mkdir /content/output\n",
        "# download models\n",
        "# first stage\n",
        "!cd /content/latent-diffusion\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/kl-f4/model.zip https://ommer-lab.com/files/latent-diffusion/kl-f4.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/kl-f8/model.zip https://ommer-lab.com/files/latent-diffusion/kl-f8.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/kl-f16/model.zip https://ommer-lab.com/files/latent-diffusion/kl-f16.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/kl-f32/model.zip https://ommer-lab.com/files/latent-diffusion/kl-f32.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/vq-f4/model.zip https://ommer-lab.com/files/latent-diffusion/vq-f4.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/vq-f4-noattn/model.zip https://ommer-lab.com/files/latent-diffusion/vq-f4-noattn.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/vq-f8/model.zip https://ommer-lab.com/files/latent-diffusion/vq-f8.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/vq-f8-n256/model.zip https://ommer-lab.com/files/latent-diffusion/vq-f8-n256.zip\n",
        "!wget -O /content/latent-diffusion/models/first_stage_models/vq-f16/model.zip https://ommer-lab.com/files/latent-diffusion/vq-f16.zip\n",
        "%cd /content/latent-diffusion/models/first_stage_models/kl-f4/\n",
        "!unzip -o model.zip\n",
        "%cd ../kl-f8\n",
        "!unzip -o model.zip\n",
        "%cd ../kl-f16\n",
        "!unzip -o model.zip\n",
        "%cd ../kl-f32\n",
        "!unzip -o model.zip\n",
        "%cd ../vq-f4\n",
        "!unzip -o model.zip\n",
        "%cd ../vq-f4-noattn\n",
        "!unzip -o model.zip\n",
        "%cd ../vq-f8\n",
        "!unzip -o model.zip\n",
        "%cd ../vq-f8-n256\n",
        "!unzip -o model.zip\n",
        "%cd ../vq-f16\n",
        "!unzip -o model.zip\n",
        "# models\n",
        "!cd /content/latent-diffusion\n",
        "!wget -O /content/latent-diffusion/models/ldm/celeba256/celeba-256.zip https://ommer-lab.com/files/latent-diffusion/celeba.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/ffhq256/ffhq-256.zip https://ommer-lab.com/files/latent-diffusion/ffhq.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/lsun_churches256/lsun_churches-256.zip https://ommer-lab.com/files/latent-diffusion/lsun_churches.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/lsun_beds256/lsun_beds-256.zip https://ommer-lab.com/files/latent-diffusion/lsun_bedrooms.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/text2img256/model.zip https://ommer-lab.com/files/latent-diffusion/text2img.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/cin256/model.zip https://ommer-lab.com/files/latent-diffusion/cin.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/semantic_synthesis512/model.zip https://ommer-lab.com/files/latent-diffusion/semantic_synthesis.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/semantic_synthesis256/model.zip https://ommer-lab.com/files/latent-diffusion/semantic_synthesis256.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/bsr_sr/model.zip https://ommer-lab.com/files/latent-diffusion/sr_bsr.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/layout2img-openimages256/model.zip https://ommer-lab.com/files/latent-diffusion/layout2img_model.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/inpainting_big/model.zip https://ommer-lab.com/files/latent-diffusion/inpainting_big.zip\n",
        "%cd /content/latent-diffusion/models/ldm/celeba256/\n",
        "!unzip -o celeba-256.zip\n",
        "%cd ../ffhq256\n",
        "!unzip -o ffhq-256.zip\n",
        "%cd ../lsun_churches256\n",
        "!unzip -o lsun_churches-256.zip\n",
        "%cd ../lsun_beds256\n",
        "!unzip -o lsun_beds-256.zip\n",
        "%cd ../text2img256\n",
        "!unzip -o model.zip\n",
        "%cd ../cin256\n",
        "!unzip -o model.zip\n",
        "%cd ../semantic_synthesis512\n",
        "!unzip -o model.zip\n",
        "%cd ../semantic_synthesis256\n",
        "!unzip -o model.zip\n",
        "%cd ../bsr_sr\n",
        "!unzip -o model.zip\n",
        "%cd ../layout2img-openimages256\n",
        "!unzip -o model.zip\n",
        "%cd ../inpainting_big\n",
        "!unzip -o model.zip\n",
        "!wget -O /content/latent-diffusion/models/ldm/inpainting_big/last.ckpt https://heibox.uni-heidelberg.de/f/4d9ac7ea40c64582b7c9/?dl=1\n",
        "# dependencies\n",
        "!pip install omegaconf pytorch_lightning einops\n",
        "!pip install git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install albumentations==0.4.3 pudb==2019.2 imageio==2.9.0 imageio-ffmpeg==0.4.2 pytorch-lightning==1.4.2 omegaconf==2.1.1 test-tube>=0.7.5 streamlit>=0.73.1 einops==0.3.0 torch-fidelity==0.3.0\n",
        "%cd /content/\n",
        "!git clone https://github.com/CompVis/taming-transformers\n",
        "%cd taming-transformers\n",
        "!pip install -e .\n",
        "# py is in the wrong folder\n",
        "!cp /content/latent-diffusion/scripts/inpaint.py /content/latent-diffusion/inpaint.py\n",
        "!cp /content/latent-diffusion/scripts/sample_diffusion.py /content/latent-diffusion/sample_diffusion.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-4IvHMcRg28A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image SR"
      ],
      "metadata": {
        "id": "-by1LD5DqSaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown if the input image is too big, comment the display() and just save the image with PIL, to avoid crashing\n",
        "%cd /content/latent-diffusion\n",
        "from notebook_helpers import run, load_model_from_config\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "import numpy as np\n",
        "import IPython.display as d\n",
        "from PIL import Image\n",
        "input_path = \"/content/input/1.png\" #@param\n",
        "steps = 100 #@param\n",
        "config = OmegaConf.load(\"/content/latent-diffusion/models/ldm/bsr_sr/config.yaml\")\n",
        "model, step = load_model_from_config(config, \"/content/latent-diffusion/models/ldm/bsr_sr/model.ckpt\")\n",
        "logs = run(model[\"model\"], input_path, \"superresolution\", steps)\n",
        "\n",
        "sample = logs[\"sample\"]\n",
        "sample = sample.detach().cpu()\n",
        "sample = torch.clamp(sample, -1., 1.)\n",
        "sample = (sample + 1.) / 2. * 255\n",
        "sample = sample.numpy().astype(np.uint8)\n",
        "sample = np.transpose(sample, (0, 2, 3, 1))\n",
        "print(sample.shape)\n",
        "a = Image.fromarray(sample[0])\n",
        "display(a)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lZJWR7inoyJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inpainting"
      ],
      "metadata": {
        "id": "8EgHBZwMmHO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inpainting\n",
        "# examples https://github.com/CompVis/latent-diffusion/tree/main/data/inpainting_examples\n",
        "%cd /content/latent-diffusion\n",
        "!python inpaint.py --indir /content/input --outdir /content/output --steps 50"
      ],
      "metadata": {
        "id": "tVxWVJfGgdUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image generation\n",
        "Inside the /content/latent-diffusion/models/ldm folder are a bunch of different models"
      ],
      "metadata": {
        "id": "gRbmaDsjmDZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# celeba image genration (256px)\n",
        "%cd /content/latent-diffusion\n",
        "!python sample_diffusion.py -r /content/latent-diffusion/models/ldm/celeba256/model.ckpt\n",
        "# output for this exmaple: /content/latent-diffusion/models/ldm/celeba256"
      ],
      "metadata": {
        "id": "nht0wPB3jbgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ffhq image generation (256px)\n",
        "%cd /content/latent-diffusion\n",
        "!python sample_diffusion.py -r /content/latent-diffusion/models/ldm/ffhq256/model.ckpt"
      ],
      "metadata": {
        "id": "r1C1KnOplOLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lsun_beds256\n",
        "%cd /content/latent-diffusion\n",
        "!python sample_diffusion.py -r /content/latent-diffusion/models/ldm/lsun_beds256/model.ckpt"
      ],
      "metadata": {
        "id": "G3TY3_dMl7vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lsun_churches256\n",
        "%cd /content/latent-diffusion\n",
        "!python sample_diffusion.py -r /content/latent-diffusion/models/ldm/lsun_churches256/model.ckpt"
      ],
      "metadata": {
        "id": "3lOHFoQZliXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}